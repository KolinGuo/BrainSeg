{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from skimage import io\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187758\n"
     ]
    }
   ],
   "source": [
    "PATH_DIR  = '/BrainSeg/classify_train_dataset/'\n",
    "paths = glob.glob(PATH_DIR + '/*/*/*.png')\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brain Dataset Object\n",
    "\n",
    "    \n",
    "# Figure out how to get the path of image\n",
    "class BrainDataSet(Dataset):\n",
    "  # Inputs:\n",
    "  # path - string containing path to a directroy of brain dataset image\n",
    "  # transform - a transform to be done on the image; defaults to none if\n",
    "  # no transforms are needed\n",
    "    def __init__(self,path,transform = None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        #self.imageList = os.listdir(self.path)\n",
    "        self.imageList = glob.glob(self.path+\"/*/*/*.png\")\n",
    "    \n",
    "  # Retrieves image at specified index and returns the image along with a label\n",
    "  # Inputs: \n",
    "  # idx - specified image index\n",
    "  # Outputs:\n",
    "  # sample - structures containing images and their corresponding labels\n",
    "    def __getitem__(self,idx):\n",
    "        img_fullpath = self.imageList[idx]\n",
    "        img_name = img_fullpath.split(\"/\")[-1]\n",
    "        image = Image.open(img_fullpath)\n",
    "        #image = Image.convert('RGB')\n",
    "#         image = image.resize((256,256))\n",
    "        # Add label\n",
    "        if img_name.startswith(\"g\"):\n",
    "            label = 2\n",
    "        if img_name.startswith(\"w\"):\n",
    "            label = 1\n",
    "        if img_name.startswith(\"b\"):\n",
    "            label = 0\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'image':image, 'label':label}\n",
    "        #print(label)\n",
    "        #print(sample)\n",
    "        return sample\n",
    "  \n",
    "  # Return the number of images in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.imageList)\n",
    "  \n",
    "  # Plot and visualize an image and its corresponding label\n",
    "    def visualize(self,idx):\n",
    "        img_fullpath = self.imageList[idx]\n",
    "        image = io.imread(img_fullpath)\n",
    "        img_name = img_fullpath.split(\"/\")[-1]\n",
    "        print('Full Path:',img_fullpath)\n",
    "        print('Image Name:',img_name)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187758\n",
      "187758 168983 18775\n"
     ]
    }
   ],
   "source": [
    "brain = BrainDataSet(PATH_DIR)\n",
    "# brain.visualize(32)\n",
    "# brain.__getitem__(90000)\n",
    "print(brain.__len__())\n",
    "# Define Parameters\n",
    "SIZE = brain.__len__()\n",
    "VAL_RATIO = 0.1\n",
    "VAL_SIZE = int(SIZE * VAL_RATIO)\n",
    "TRAIN_SIZE = SIZE - VAL_SIZE\n",
    "print(SIZE, TRAIN_SIZE, VAL_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': array([0.77906426, 0.74919518, 0.77529276]), 'std': array([0.13986633, 0.15931302, 0.17665639])}\n"
     ]
    }
   ],
   "source": [
    "NORM_PATH = '/BrainSeg/normalization.npy'\n",
    "norm = np.load(NORM_PATH,allow_pickle=True).item()\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Train_Val(PATH_DIR, norm, TRAIN_SIZE, VAL_SIZE, batch_size):\n",
    "    # PATH = '/content/drive/My Drive/brain training/training_dataset'\n",
    "    Train_Dataset = BrainDataSet(PATH_DIR,\n",
    "    #                             train = True,\n",
    "                              transform = transforms.Compose([\n",
    "#                               transforms.Resize((256,256)),\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              transforms.RandomVerticalFlip(),\n",
    "                              transforms.RandomRotation(180),\n",
    "                              transforms.ColorJitter(brightness=0.1, contrast=0.2,saturation=0.2, hue=0.02),\n",
    "                              transforms.RandomAffine(0, translate=(0.05,0.05), scale=(0.9,1.1), shear=10),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize(norm['mean'], norm['std'])\n",
    "                              ]))\n",
    "    #   train_data, val_data = torch.utils.data.dataset.random_split(Train_Dataset, (TRAIN_SIZE, VAL_SIZE))\n",
    "    train_data, val_data = torch.utils.data.random_split(Train_Dataset, (TRAIN_SIZE, VAL_SIZE))\n",
    "    print('The size of train data: ', len(train_data))\n",
    "    print('The size of val data: ', len(val_data))\n",
    "    #   print(len(train_data))\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                             batch_size = batch_size, shuffle = True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                             batch_size = batch_size, shuffle=True)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train data:  168983\n",
      "The size of val data:  18775\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fae26806eb8>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fae26806320>\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = Load_Train_Val(PATH_DIR, norm, TRAIN_SIZE, VAL_SIZE, batch_size = 16)\n",
    "print(train_loader)\n",
    "print(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from model import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs,3)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_train(model, loss_func, optimizer, lr_scheduler, num_epochs, PATH, train_loader, val_loader, number):\n",
    "  \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader,0):\n",
    "            inputs = data['image']\n",
    "            labels = data['label']\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 400 == 399:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 200))\n",
    "                running_loss = 0.0\n",
    "        end = time.time()\n",
    "        print(\"Train Time:\", end-start)\n",
    "        print(\"Traing finished\", epoch+1, \"epochs\")\n",
    "\n",
    "    #     MODEL_NAME_1 = 'ResNet18_' + str(number) + '.pkl'\n",
    "        MODEL_PATH_1 = PATH + '/' + 'self-attention_' + str(number) + '.pkl'\n",
    "    #     MODEL_NAME_2 = 'ResNet18_params_' + str(number) + '.pkl'\n",
    "    #     MODEL_PATH_2 = PATH + '/' + 'ResNet18_params_' + str(number) + '.pkl'\n",
    "        #     torch.save(model, MODEL_NAME_1)\n",
    "        torch.save(model, MODEL_PATH_1)\n",
    "        #     torch.save(model.state_dict(), MODEL_NAME_2)\n",
    "    #     torch.save(model.state_dict(), MODEL_PATH_2)\n",
    "        number = number + 1\n",
    "\n",
    "\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        window = 200\n",
    "        start = time.time()\n",
    "        for i_val, data_val in enumerate(val_loader,0):\n",
    "            img_val = data_val['image']\n",
    "            label_val = data_val['label']\n",
    "            img_val, label_val = Variable(img_val), Variable(label_val)\n",
    "            img_val = img_val.cuda()\n",
    "            label_val = label_val.cuda()\n",
    "\n",
    "            predict = model(img_val)\n",
    "            loss_val = loss_func(predict, label_val)\n",
    "            val_loss += loss_val.item()\n",
    "            _, predict = torch.max(predict.data, 1)\n",
    "            total += label_val.size(0)\n",
    "            correct += (label_val == predict).sum().item()\n",
    "            if i_val % window == window-1:    # print every 2000 mini-batches\n",
    "                print('[%5d] val_loss: %.3f' %\n",
    "                        (i_val + 1, val_loss / window))\n",
    "                val_loss = 0.0\n",
    "        print('Accuracy = %.6f' % (100 * correct / total))\n",
    "        end = time.time()\n",
    "        print('val_time', end - start)\n",
    "\n",
    "    print('Finished Training')\n",
    "    torch.save(model, MODEL_PATH_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss: 1.085\n",
      "[1,   800] loss: 0.936\n",
      "[1,  1200] loss: 0.883\n",
      "[1,  1600] loss: 0.895\n",
      "[1,  2000] loss: 0.834\n",
      "[1,  2400] loss: 0.732\n",
      "[1,  2800] loss: 0.717\n",
      "[1,  3200] loss: 0.704\n",
      "[1,  3600] loss: 0.703\n",
      "[1,  4000] loss: 0.638\n",
      "[1,  4400] loss: 0.617\n",
      "[1,  4800] loss: 0.607\n",
      "[1,  5200] loss: 0.572\n",
      "[1,  5600] loss: 0.549\n",
      "[1,  6000] loss: 0.580\n",
      "[1,  6400] loss: 0.564\n",
      "[1,  6800] loss: 0.581\n",
      "[1,  7200] loss: 0.552\n",
      "[1,  7600] loss: 0.502\n",
      "[1,  8000] loss: 0.510\n",
      "[1,  8400] loss: 0.557\n",
      "[1,  8800] loss: 0.476\n",
      "[1,  9200] loss: 0.502\n",
      "[1,  9600] loss: 0.504\n",
      "[1, 10000] loss: 0.510\n",
      "[1, 10400] loss: 0.489\n",
      "[1, 10800] loss: 0.488\n",
      "[1, 11200] loss: 0.475\n",
      "[1, 11600] loss: 0.483\n",
      "[1, 12000] loss: 0.468\n",
      "[1, 12400] loss: 0.454\n",
      "[1, 12800] loss: 0.467\n",
      "[1, 13200] loss: 0.473\n",
      "[1, 13600] loss: 0.465\n",
      "[1, 14000] loss: 0.475\n",
      "[1, 14400] loss: 0.488\n",
      "[1, 14800] loss: 0.444\n",
      "[1, 15200] loss: 0.459\n",
      "[1, 15600] loss: 0.487\n",
      "[1, 16000] loss: 0.504\n",
      "[1, 16400] loss: 0.449\n",
      "[1, 16800] loss: 0.417\n",
      "[1, 17200] loss: 0.450\n",
      "[1, 17600] loss: 0.455\n",
      "[1, 18000] loss: 0.446\n",
      "[1, 18400] loss: 0.419\n",
      "Train Time: 2985.337925672531\n",
      "Traing finished 1 epochs\n",
      "[  200] val_loss: 0.218\n",
      "[  400] val_loss: 0.187\n",
      "[  600] val_loss: 0.232\n",
      "[  800] val_loss: 0.251\n",
      "[ 1000] val_loss: 0.214\n",
      "[ 1200] val_loss: 0.182\n",
      "[ 1400] val_loss: 0.199\n",
      "[ 1600] val_loss: 0.213\n",
      "[ 1800] val_loss: 0.221\n",
      "[ 2000] val_loss: 0.218\n",
      "[ 2200] val_loss: 0.220\n",
      "[ 2400] val_loss: 0.220\n",
      "[ 2600] val_loss: 0.208\n",
      "[ 2800] val_loss: 0.229\n",
      "[ 3000] val_loss: 0.212\n",
      "[ 3200] val_loss: 0.232\n",
      "[ 3400] val_loss: 0.190\n",
      "[ 3600] val_loss: 0.205\n",
      "[ 3800] val_loss: 0.197\n",
      "[ 4000] val_loss: 0.208\n",
      "[ 4200] val_loss: 0.175\n",
      "[ 4400] val_loss: 0.236\n",
      "[ 4600] val_loss: 0.183\n",
      "Accuracy = 92.663311\n",
      "val_time 627.4879267215729\n",
      "[2,   400] loss: 0.382\n",
      "[2,   800] loss: 0.427\n",
      "[2,  1200] loss: 0.447\n",
      "[2,  1600] loss: 0.423\n",
      "[2,  2000] loss: 0.427\n",
      "[2,  2400] loss: 0.399\n",
      "[2,  2800] loss: 0.412\n",
      "[2,  3200] loss: 0.393\n",
      "[2,  3600] loss: 0.445\n",
      "[2,  4000] loss: 0.418\n",
      "[2,  4400] loss: 0.386\n",
      "[2,  4800] loss: 0.383\n",
      "[2,  5200] loss: 0.403\n",
      "[2,  5600] loss: 0.396\n",
      "[2,  6000] loss: 0.409\n",
      "[2,  6400] loss: 0.366\n",
      "[2,  6800] loss: 0.453\n",
      "[2,  7200] loss: 0.403\n",
      "[2,  7600] loss: 0.427\n",
      "[2,  8000] loss: 0.393\n",
      "[2,  8400] loss: 0.455\n",
      "[2,  8800] loss: 0.402\n",
      "[2,  9200] loss: 0.415\n",
      "[2,  9600] loss: 0.399\n",
      "[2, 10000] loss: 0.382\n",
      "[2, 10400] loss: 0.405\n",
      "[2, 10800] loss: 0.449\n",
      "[2, 11200] loss: 0.414\n",
      "[2, 11600] loss: 0.392\n",
      "[2, 12000] loss: 0.425\n",
      "[2, 12400] loss: 0.373\n",
      "[2, 12800] loss: 0.389\n",
      "[2, 13200] loss: 0.407\n",
      "[2, 13600] loss: 0.404\n",
      "[2, 14000] loss: 0.397\n",
      "[2, 14400] loss: 0.367\n",
      "[2, 14800] loss: 0.372\n",
      "[2, 15200] loss: 0.400\n",
      "[2, 15600] loss: 0.387\n",
      "[2, 16000] loss: 0.449\n",
      "[2, 16400] loss: 0.410\n",
      "[2, 16800] loss: 0.346\n",
      "[2, 17200] loss: 0.394\n",
      "[2, 17600] loss: 0.394\n",
      "[2, 18000] loss: 0.375\n",
      "[2, 18400] loss: 0.425\n",
      "Train Time: 2480.391021966934\n",
      "Traing finished 2 epochs\n",
      "[  200] val_loss: 0.222\n",
      "[  400] val_loss: 0.190\n",
      "[  600] val_loss: 0.247\n",
      "[  800] val_loss: 0.208\n",
      "[ 1000] val_loss: 0.205\n",
      "[ 1200] val_loss: 0.235\n",
      "[ 1400] val_loss: 0.204\n",
      "[ 1600] val_loss: 0.248\n",
      "[ 1800] val_loss: 0.205\n",
      "[ 2000] val_loss: 0.224\n",
      "[ 2200] val_loss: 0.218\n",
      "[ 2400] val_loss: 0.240\n",
      "[ 2600] val_loss: 0.216\n",
      "[ 2800] val_loss: 0.227\n",
      "[ 3000] val_loss: 0.221\n",
      "[ 3200] val_loss: 0.212\n",
      "[ 3400] val_loss: 0.217\n",
      "[ 3600] val_loss: 0.189\n",
      "[ 3800] val_loss: 0.187\n",
      "[ 4000] val_loss: 0.212\n",
      "[ 4200] val_loss: 0.220\n",
      "[ 4400] val_loss: 0.239\n",
      "[ 4600] val_loss: 0.182\n",
      "Accuracy = 92.362387\n",
      "val_time 510.3634810447693\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "lr_scheduler = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_scheduler)\n",
    "num_epochs = 2\n",
    "PATH = '/BrainSeg/Classify_Results/self-attention/'\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)\n",
    "number = 0\n",
    "resnet_train(model, loss_func, optimizer, lr_scheduler, num_epochs, PATH, train_loader, val_loader, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss: 0.287\n",
      "[1,   800] loss: 0.310\n",
      "[1,  1200] loss: 0.297\n",
      "[1,  1600] loss: 0.297\n",
      "[1,  2000] loss: 0.314\n",
      "[1,  2400] loss: 0.295\n",
      "[1,  2800] loss: 0.337\n",
      "[1,  3200] loss: 0.291\n",
      "[1,  3600] loss: 0.314\n",
      "[1,  4000] loss: 0.308\n",
      "[1,  4400] loss: 0.315\n",
      "[1,  4800] loss: 0.302\n",
      "[1,  5200] loss: 0.283\n",
      "[1,  5600] loss: 0.317\n",
      "[1,  6000] loss: 0.329\n",
      "[1,  6400] loss: 0.299\n",
      "[1,  6800] loss: 0.295\n",
      "[1,  7200] loss: 0.322\n",
      "[1,  7600] loss: 0.319\n",
      "[1,  8000] loss: 0.290\n",
      "[1,  8400] loss: 0.319\n",
      "[1,  8800] loss: 0.326\n",
      "[1,  9200] loss: 0.319\n",
      "[1,  9600] loss: 0.314\n",
      "[1, 10000] loss: 0.296\n",
      "[1, 10400] loss: 0.291\n",
      "Train Time: 2718.768818616867\n",
      "Traing finished 1 epochs\n",
      "[  200] val_loss: 0.143\n",
      "[  400] val_loss: 0.160\n",
      "[  600] val_loss: 0.142\n",
      "[  800] val_loss: 0.152\n",
      "[ 1000] val_loss: 0.148\n",
      "Accuracy = 95.147803\n",
      "val_time 249.33393168449402\n",
      "[2,   400] loss: 0.324\n",
      "[2,   800] loss: 0.279\n",
      "[2,  1200] loss: 0.286\n",
      "[2,  1600] loss: 0.285\n",
      "[2,  2000] loss: 0.329\n",
      "[2,  2400] loss: 0.312\n",
      "[2,  2800] loss: 0.326\n",
      "[2,  3200] loss: 0.321\n",
      "[2,  3600] loss: 0.315\n",
      "[2,  4000] loss: 0.309\n",
      "[2,  4400] loss: 0.284\n",
      "[2,  4800] loss: 0.308\n",
      "[2,  5200] loss: 0.314\n",
      "[2,  5600] loss: 0.298\n",
      "[2,  6000] loss: 0.315\n",
      "[2,  6400] loss: 0.319\n",
      "[2,  6800] loss: 0.298\n",
      "[2,  7200] loss: 0.318\n",
      "[2,  7600] loss: 0.291\n",
      "[2,  8000] loss: 0.302\n",
      "[2,  8400] loss: 0.307\n",
      "[2,  8800] loss: 0.301\n",
      "[2,  9200] loss: 0.300\n",
      "[2,  9600] loss: 0.311\n",
      "[2, 10000] loss: 0.331\n",
      "[2, 10400] loss: 0.291\n",
      "Train Time: 2663.628318309784\n",
      "Traing finished 2 epochs\n",
      "[  200] val_loss: 0.159\n",
      "[  400] val_loss: 0.152\n",
      "[  600] val_loss: 0.136\n",
      "[  800] val_loss: 0.152\n",
      "[ 1000] val_loss: 0.155\n",
      "Accuracy = 95.153129\n",
      "val_time 249.51556754112244\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/BrainSeg/Classify_Results/self-attention/self-attention_12.pkl')\n",
    "model = model.cuda()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lr_scheduler = 0.00001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_scheduler)\n",
    "num_epochs = 2\n",
    "PATH = '/BrainSeg/Classify_Results/self-attention/'\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)\n",
    "number = 13\n",
    "resnet_train(model, loss_func, optimizer, lr_scheduler, num_epochs, PATH, train_loader, val_loader, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 23 10:05:41 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN Xp            Off  | 00000000:65:00.0 Off |                  N/A |\r\n",
      "| 23%   31C    P8    17W / 250W |  12099MiB / 12194MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
