{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdUSlz0Y9VSh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from skimage import io\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xd1mM3q69VSj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tz7imB0i9VSm"
   },
   "outputs": [],
   "source": [
    "PATH_DIR  = '/BrainSeg/classify_train_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brain Dataset Object\n",
    "\n",
    "    \n",
    "# Figure out how to get the path of image\n",
    "class BrainDataSet(Dataset):\n",
    "  # Inputs:\n",
    "  # path - string containing path to a directroy of brain dataset image\n",
    "  # transform - a transform to be done on the image; defaults to none if\n",
    "  # no transforms are needed\n",
    "    def __init__(self,path,transform = None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        #self.imageList = os.listdir(self.path)\n",
    "        self.imageList = glob.glob(self.path+\"/*/*/*.png\")\n",
    "    \n",
    "  # Retrieves image at specified index and returns the image along with a label\n",
    "  # Inputs: \n",
    "  # idx - specified image index\n",
    "  # Outputs:\n",
    "  # sample - structures containing images and their corresponding labels\n",
    "    def __getitem__(self,idx):\n",
    "        img_fullpath = self.imageList[idx]\n",
    "        img_name = img_fullpath.split(\"/\")[-1]\n",
    "        image = Image.open(img_fullpath)\n",
    "        #image = Image.convert('RGB')\n",
    "\n",
    "        # Add label\n",
    "        if img_name.startswith(\"g\"):\n",
    "            label = 2\n",
    "        if img_name.startswith(\"w\"):\n",
    "            label = 1\n",
    "        if img_name.startswith(\"b\"):\n",
    "            label = 0\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'image':image, 'label':label}\n",
    "        #print(label)\n",
    "        #print(sample)\n",
    "        return sample\n",
    "  \n",
    "  # Return the number of images in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.imageList)\n",
    "  \n",
    "  # Plot and visualize an image and its corresponding label\n",
    "    def visualize(self,idx):\n",
    "        img_fullpath = self.imageList[idx]\n",
    "        image = io.imread(img_fullpath)\n",
    "        img_name = img_fullpath.split(\"/\")[-1]\n",
    "        print('Full Path:',img_fullpath)\n",
    "        print('Image Name:',img_name)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRHcoBy09VSt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187758 150207 37551\n"
     ]
    }
   ],
   "source": [
    "brain = BrainDataSet(PATH_DIR)\n",
    "\n",
    "# Define Parameters\n",
    "SIZE = brain.__len__()\n",
    "VAL_RATIO = 0.2\n",
    "VAL_SIZE = int(SIZE * VAL_RATIO)\n",
    "TRAIN_SIZE = SIZE - VAL_SIZE\n",
    "print(SIZE, TRAIN_SIZE, VAL_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTca2CxD9VSw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': array([0.77906426, 0.74919518, 0.77529276]), 'std': array([0.13986633, 0.15931302, 0.17665639])}\n"
     ]
    }
   ],
   "source": [
    "NORM_PATH = '/BrainSeg/normalization.npy'\n",
    "norm = np.load(NORM_PATH,allow_pickle=True).item()\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2h8YAQ4n9VS0"
   },
   "outputs": [],
   "source": [
    "def Load_Train_Val(PATH_DIR, norm, TRAIN_SIZE, VAL_SIZE, batch_size):\n",
    "    # PATH = '/content/drive/My Drive/brain training/training_dataset'\n",
    "    Train_Dataset = BrainDataSet(PATH_DIR,\n",
    "    #                             train = True,\n",
    "                              transform = transforms.Compose([\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              transforms.RandomVerticalFlip(),\n",
    "                              transforms.RandomRotation(180),\n",
    "                              transforms.ColorJitter(brightness=0.1, contrast=0.2,saturation=0.2, hue=0.02),\n",
    "                              transforms.RandomAffine(0, translate=(0.05,0.05), scale=(0.9,1.1), shear=10),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize(norm['mean'], norm['std'])\n",
    "                              ]))\n",
    "    #   train_data, val_data = torch.utils.data.dataset.random_split(Train_Dataset, (TRAIN_SIZE, VAL_SIZE))\n",
    "    train_data, val_data = torch.utils.data.random_split(Train_Dataset, (TRAIN_SIZE, VAL_SIZE))\n",
    "    print('The size of train data: ', len(train_data))\n",
    "    print('The size of val data: ', len(val_data))\n",
    "    #   print(len(train_data))\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                             batch_size = batch_size, shuffle = True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                             batch_size = batch_size, shuffle=True)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IMwDrSo9VS1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train data:  150207\n",
      "The size of val data:  37551\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fce55b9efd0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fce55b9ef60>\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = Load_Train_Val(PATH_DIR, norm, TRAIN_SIZE, VAL_SIZE, batch_size = 16)\n",
    "print(train_loader)\n",
    "print(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vj8LbgHV9VS3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_train(model, loss_func, optimizer, lr_scheduler, num_epochs, PATH, train_loader, val_loader, number):\n",
    "  \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader,0):\n",
    "            inputs = data['image']\n",
    "            labels = data['label']\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 400 == 399:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 200))\n",
    "                running_loss = 0.0\n",
    "        end = time.time()\n",
    "        print(\"Train Time:\", end-start)\n",
    "        print(\"Traing finished\", epoch+1, \"epochs\")\n",
    "\n",
    "    #     MODEL_NAME_1 = 'resnext50_32x4d_' + str(number) + '.pkl'\n",
    "        MODEL_PATH_1 = PATH + '/' + 'Densenet_' + str(number) + '.pkl'\n",
    "    #     MODEL_NAME_2 = 'resnext50_32x4d_params_' + str(number) + '.pkl'\n",
    "    #     MODEL_PATH_2 = PATH + '/' + 'resnext50_32x4d_params_' + str(number) + '.pkl'\n",
    "        #     torch.save(model, MODEL_NAME_1)\n",
    "        torch.save(model, MODEL_PATH_1)\n",
    "        #     torch.save(model.state_dict(), MODEL_NAME_2)\n",
    "    #     torch.save(model.state_dict(), MODEL_PATH_2)\n",
    "        number = number + 1\n",
    "\n",
    "\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        window = 200\n",
    "        start = time.time()\n",
    "        for i_val, data_val in enumerate(val_loader,0):\n",
    "            img_val = data_val['image']\n",
    "            label_val = data_val['label']\n",
    "            img_val, label_val = Variable(img_val), Variable(label_val)\n",
    "            img_val = img_val.cuda()\n",
    "            label_val = label_val.cuda()\n",
    "\n",
    "            predict = model(img_val)\n",
    "            loss_val = loss_func(predict, label_val)\n",
    "            val_loss += loss_val.item()\n",
    "            _, predict = torch.max(predict.data, 1)\n",
    "            total += label_val.size(0)\n",
    "            correct += (label_val == predict).sum().item()\n",
    "            if i_val % window == window-1:    # print every 2000 mini-batches\n",
    "                print('[%5d] val_loss: %.3f' %\n",
    "                        (i_val + 1, val_loss / window))\n",
    "                val_loss = 0.0\n",
    "        print('Accuracy = %.6f' % (100 * correct / total))\n",
    "        end = time.time()\n",
    "        print('val_time', end - start)\n",
    "\n",
    "    print('Finished Training')\n",
    "    torch.save(model, MODEL_PATH_1)\n",
    "#   torch.save(model.state_dict(), MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNOqKZhS9VS-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss: 0.321\n",
      "[1,   800] loss: 0.319\n",
      "[1,  1200] loss: 0.318\n",
      "[1,  1600] loss: 0.301\n",
      "[1,  2000] loss: 0.325\n",
      "[1,  2400] loss: 0.308\n",
      "[1,  2800] loss: 0.298\n",
      "[1,  3200] loss: 0.311\n",
      "[1,  3600] loss: 0.312\n",
      "[1,  4000] loss: 0.307\n",
      "[1,  4400] loss: 0.305\n",
      "[1,  4800] loss: 0.289\n",
      "[1,  5200] loss: 0.322\n",
      "[1,  5600] loss: 0.305\n",
      "[1,  6000] loss: 0.316\n",
      "[1,  6400] loss: 0.309\n",
      "[1,  6800] loss: 0.309\n",
      "[1,  7200] loss: 0.305\n",
      "[1,  7600] loss: 0.289\n",
      "[1,  8000] loss: 0.296\n",
      "[1,  8400] loss: 0.306\n",
      "[1,  8800] loss: 0.292\n",
      "[1,  9200] loss: 0.299\n",
      "Train Time: 27913.582228422165\n",
      "Traing finished 1 epochs\n",
      "[  200] val_loss: 0.146\n",
      "[  400] val_loss: 0.143\n",
      "[  600] val_loss: 0.141\n",
      "[  800] val_loss: 0.157\n",
      "[ 1000] val_loss: 0.161\n",
      "[ 1200] val_loss: 0.134\n",
      "[ 1400] val_loss: 0.150\n",
      "[ 1600] val_loss: 0.147\n",
      "[ 1800] val_loss: 0.136\n",
      "[ 2000] val_loss: 0.146\n",
      "[ 2200] val_loss: 0.134\n",
      "Accuracy = 95.195867\n",
      "val_time 4790.173046350479\n",
      "[2,   400] loss: 0.310\n",
      "[2,   800] loss: 0.309\n",
      "[2,  1200] loss: 0.285\n",
      "[2,  1600] loss: 0.284\n",
      "[2,  2000] loss: 0.281\n",
      "[2,  2400] loss: 0.306\n",
      "[2,  2800] loss: 0.267\n",
      "[2,  3200] loss: 0.290\n",
      "[2,  3600] loss: 0.292\n",
      "[2,  4000] loss: 0.296\n",
      "[2,  4400] loss: 0.270\n",
      "[2,  4800] loss: 0.327\n",
      "[2,  5200] loss: 0.339\n",
      "[2,  5600] loss: 0.282\n",
      "[2,  6000] loss: 0.291\n",
      "[2,  6400] loss: 0.280\n",
      "[2,  6800] loss: 0.320\n",
      "[2,  7200] loss: 0.282\n",
      "[2,  7600] loss: 0.287\n",
      "[2,  8000] loss: 0.271\n",
      "[2,  8400] loss: 0.287\n",
      "[2,  8800] loss: 0.324\n",
      "[2,  9200] loss: 0.292\n",
      "Train Time: 14420.164456129074\n",
      "Traing finished 2 epochs\n",
      "[  200] val_loss: 0.151\n",
      "[  400] val_loss: 0.154\n",
      "[  600] val_loss: 0.145\n",
      "[  800] val_loss: 0.140\n",
      "[ 1000] val_loss: 0.148\n",
      "[ 1200] val_loss: 0.141\n",
      "[ 1400] val_loss: 0.146\n",
      "[ 1600] val_loss: 0.140\n",
      "[ 1800] val_loss: 0.126\n",
      "[ 2000] val_loss: 0.152\n",
      "[ 2200] val_loss: 0.116\n",
      "Accuracy = 95.454182\n",
      "val_time 556.040863275528\n",
      "[3,   400] loss: 0.264\n",
      "[3,   800] loss: 0.312\n",
      "[3,  1200] loss: 0.317\n",
      "[3,  1600] loss: 0.284\n",
      "[3,  2000] loss: 0.295\n",
      "[3,  2400] loss: 0.295\n",
      "[3,  2800] loss: 0.303\n",
      "[3,  3200] loss: 0.279\n",
      "[3,  3600] loss: 0.288\n",
      "[3,  4000] loss: 0.292\n",
      "[3,  4400] loss: 0.277\n",
      "[3,  4800] loss: 0.317\n",
      "[3,  5200] loss: 0.286\n",
      "[3,  5600] loss: 0.278\n",
      "[3,  6000] loss: 0.266\n",
      "[3,  6400] loss: 0.289\n",
      "[3,  6800] loss: 0.295\n",
      "[3,  7200] loss: 0.269\n",
      "[3,  7600] loss: 0.269\n",
      "[3,  8000] loss: 0.311\n",
      "[3,  8400] loss: 0.274\n",
      "[3,  8800] loss: 0.271\n",
      "[3,  9200] loss: 0.259\n",
      "Train Time: 3097.495091199875\n",
      "Traing finished 3 epochs\n",
      "[  200] val_loss: 0.132\n",
      "[  400] val_loss: 0.132\n",
      "[  600] val_loss: 0.138\n",
      "[  800] val_loss: 0.155\n",
      "[ 1000] val_loss: 0.148\n",
      "[ 1200] val_loss: 0.137\n",
      "[ 1400] val_loss: 0.128\n",
      "[ 1600] val_loss: 0.130\n",
      "[ 1800] val_loss: 0.132\n",
      "[ 2000] val_loss: 0.139\n",
      "[ 2200] val_loss: 0.161\n",
      "Accuracy = 95.416900\n",
      "val_time 556.6569669246674\n",
      "[4,   400] loss: 0.265\n",
      "[4,   800] loss: 0.310\n",
      "[4,  1200] loss: 0.264\n",
      "[4,  1600] loss: 0.288\n",
      "[4,  2000] loss: 0.283\n",
      "[4,  2400] loss: 0.283\n",
      "[4,  2800] loss: 0.287\n",
      "[4,  3200] loss: 0.267\n",
      "[4,  3600] loss: 0.276\n",
      "[4,  4000] loss: 0.300\n",
      "[4,  4400] loss: 0.273\n",
      "[4,  4800] loss: 0.269\n",
      "[4,  5200] loss: 0.264\n",
      "[4,  5600] loss: 0.295\n",
      "[4,  6000] loss: 0.293\n",
      "[4,  6400] loss: 0.272\n",
      "[4,  6800] loss: 0.284\n",
      "[4,  7200] loss: 0.270\n",
      "[4,  7600] loss: 0.257\n",
      "[4,  8000] loss: 0.263\n",
      "[4,  8400] loss: 0.265\n",
      "[4,  8800] loss: 0.293\n",
      "[4,  9200] loss: 0.271\n",
      "Train Time: 3158.7809076309204\n",
      "Traing finished 4 epochs\n",
      "[  200] val_loss: 0.142\n",
      "[  400] val_loss: 0.137\n",
      "[  600] val_loss: 0.138\n",
      "[  800] val_loss: 0.153\n",
      "[ 1000] val_loss: 0.140\n",
      "[ 1200] val_loss: 0.146\n",
      "[ 1400] val_loss: 0.131\n",
      "[ 1600] val_loss: 0.144\n",
      "[ 1800] val_loss: 0.143\n",
      "[ 2000] val_loss: 0.118\n",
      "[ 2200] val_loss: 0.127\n",
      "Accuracy = 95.382280\n",
      "val_time 557.1533708572388\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/BrainSeg/Classify_Results/DenseNet/Densenet_4.pkl')\n",
    "model = model.cuda()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lr_scheduler = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_scheduler)\n",
    "num_epochs = 5\n",
    "PATH = '/BrainSeg/Classify_Results/DenseNet/'\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)\n",
    "number = 4\n",
    "resnet_train(model, loss_func, optimizer, lr_scheduler, num_epochs, PATH, train_loader, val_loader, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWJ2dInW9VTA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zzh3v0n4_52L"
   },
   "outputs": [],
   "source": [
    "model_densenet = models.densenet121(pretrained=True)\n",
    "num_ftrs = model_densenet.classifier.in_features\n",
    "model_densenet.classifier = nn.Linear(num_ftrs, 3)\n",
    "model_densenet = model_densenet.cuda()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Zihan_Wang_Classify_Train.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
