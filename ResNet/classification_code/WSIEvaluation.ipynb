{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0 0.5.0\n"
     ]
    }
   ],
   "source": [
    "import pyvips\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "import time, os, copy, datetime, glob\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "format_to_dtype = {\n",
    "    'uchar': np.uint8,\n",
    "    'char': np.int8,\n",
    "    'ushort': np.uint16,\n",
    "    'short': np.int16,\n",
    "    'uint': np.uint32,\n",
    "    'int': np.int32,\n",
    "    'float': np.float32,\n",
    "    'double': np.float64,\n",
    "    'complex': np.complex64,\n",
    "    'dpcomplex': np.complex128,\n",
    "}\n",
    "\n",
    "# vips image to numpy array\n",
    "def vips2numpy(vi):\n",
    "    return np.ndarray(buffer=vi.write_to_memory(),\n",
    "                      dtype=format_to_dtype[vi.format],\n",
    "                      shape=[vi.height, vi.width, vi.bands])\n",
    "print(torch.__version__, torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': array([0.77906426, 0.74919518, 0.77529276]), 'std': array([0.13986633, 0.15931302, 0.17665639])}\n"
     ]
    }
   ],
   "source": [
    "NORM_PATH = '/BrainSeg/normalization.npy'\n",
    "norm = np.load(NORM_PATH,allow_pickle=True).item()\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "#                           transforms.RandomHorizontalFlip(),\n",
    "#                           # transforms.Resize((32,32)),\n",
    "#                           transforms.RandomVerticalFlip(),\n",
    "#                           transforms.RandomRotation(180),\n",
    "#                           transforms.ColorJitter(brightness=0.1, contrast=0.2,saturation=0.2, hue=0.02),\n",
    "#                           transforms.RandomAffine(0, translate=(0.05,0.05), scale=(0.9,1.1), shear=10),\n",
    "                          transforms.ToTensor(),\n",
    "#                           transforms.Normalize(norm['mean'], norm['std'])\n",
    "                          ])\n",
    "# from PIL import Image\n",
    "# from torch.autograd import Variable as V\n",
    "# model = torch.load(BASE_DIR + 'new_train/resnet18_3.pkl')\n",
    "model = torch.load('/BrainSeg/Checkpoints/new_LF/ResNet18_19.pkl')\n",
    "model = model.cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/BrainSeg/Classify_Results/HE0801/GMBData/\n",
      "/BrainSeg/Classify_Results/HE0801/GMBMasks/\n",
      "Run for the following 29 images out of 29 images:\n",
      " ['NA3777-02_HE.png', 'NA4077-02_HE.png', 'NA4092-02_HE.png', 'NA4107-02_HE.png', 'NA4160-02_HE.png', 'NA4195-02_HE.png', 'NA4256-02_HE.png', 'NA4299-02_HE.png', 'NA4391-02_HE.png', 'NA4463-02_HE.png', 'NA4471-02_HE.png', 'NA4553-02_HE.png', 'NA4626-02_HE.png', 'NA4672-02_HE.png', 'NA4675-02_HE.png', 'NA4691-02_HE.png', 'NA4695-02_HE.png', 'NA4894-02_HE.png', 'NA4907-02_HE.png', 'NA4944-02_HE.png', 'NA4945-02_HE.png', 'NA4967-02_HE.png', 'NA4971-02_HE.png', 'NA4972-02_HE.png', 'NA4992-02_HE.png', 'NA4993-02_HE.png', 'NA5010-02_HE.png', 'NA5015-02_HE.png', 'NA5029-02_HE.png']\n"
     ]
    }
   ],
   "source": [
    "# Specify images to run\n",
    "BASE_DIR = '/BrainSeg/'\n",
    "IMG_DIR  = BASE_DIR + 'HE_PNG/'\n",
    "SAVE_DATA_DIR = BASE_DIR + 'Classify_Results/HE0801/GMBData/'\n",
    "if not os.path.exists(SAVE_DATA_DIR):\n",
    "    os.makedirs(SAVE_DATA_DIR)\n",
    "print(SAVE_DATA_DIR)\n",
    "SAVE_IMG_DIR = BASE_DIR + 'Classify_Results/HE0801/GMBMasks/'\n",
    "if not os.path.exists(SAVE_IMG_DIR):\n",
    "    os.makedirs(SAVE_IMG_DIR)\n",
    "print(SAVE_IMG_DIR)\n",
    "\n",
    "filenames = glob.glob(IMG_DIR + '*.png')\n",
    "filenames = [filename.split('/')[-1] for filename in filenames]\n",
    "filenames = sorted(filenames)\n",
    "total_image_num = len(filenames)\n",
    "\n",
    "idx_image_to_eval = slice(0,30)      # Modify this line to select images to eval\n",
    "filenames = filenames[idx_image_to_eval]\n",
    "print('Run for the following %d images out of %d images:\\n' % (len(filenames), total_image_num), filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image NA3777-02_HE.png - (53784, 44411):   0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image NA4077-02_HE.png - (73704, 44001):   3%|▎         | 1/29 [38:20<17:53:43, 2300.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image NA4092-02_HE.png - (63744, 45102):   7%|▋         | 2/29 [1:29:52<19:02:05, 2537.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# Start evaluating\n",
    "t = tqdm(total=len(filenames))\n",
    "# print(filenames)\n",
    "for filename in filenames:\n",
    "  # print(filename)\n",
    "  # in_img = np.array(Image.open(IMG_DIR + filename)) # Out of RAM\n",
    "    in_img = pyvips.Image.new_from_file(IMG_DIR + filename)\n",
    "  \n",
    "    t.set_description_str(\"Image \" + filename + ' - (%d, %d)' % (in_img.width, in_img.height))\n",
    "    t.refresh()\n",
    "    t.write(\"\", end=' ')\n",
    "\n",
    "    num_cols = int(in_img.width/128)\n",
    "    num_rows = int(in_img.height/128)\n",
    "    nums = np.zeros((num_rows, num_cols), dtype='uint8')\n",
    "#     PRED = np.zeros((num_rows, num_cols, 3), dtype='uint8')\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "      #print('i, j = {}, {}'.format(i, j))\n",
    "            w, h = 256, 256\n",
    "            if i == num_rows - 1: # if at last row\n",
    "                h = 128\n",
    "            if j == num_cols - 1: # if at last column\n",
    "                w = 128\n",
    "            tile_img = in_img.extract_area(128*j,128*i,w,h) # c, r, w, h\n",
    "            tile_img = vips2numpy(tile_img)\n",
    "          #print(tile_img.shape)\n",
    "            if i == num_rows - 1: # if at last row\n",
    "                tile_img = np.pad(tile_img, ((0, 128),(0, 0),(0, 0)), 'constant', constant_values=((0, 0),))\n",
    "        #print('i, j = {}, {}'.format(i, j), tile_img.shape)\n",
    "            if j == num_cols - 1: # if at last column\n",
    "                tile_img = np.pad(tile_img, ((0, 0),(0, 128),(0, 0)), 'constant', constant_values=((0, 0),))\n",
    "        #print('i, j = {}, {}'.format(i, j), tile_img.shape)\n",
    "            tile_img = Image.fromarray(tile_img, 'RGB')\n",
    "            tile_img = trans(tile_img)\n",
    "            tile_img = tile_img.unsqueeze(0)\n",
    "            tile_img = Variable(tile_img)\n",
    "            tile_img = tile_img.cuda()\n",
    "            predict = model(tile_img)\n",
    "\n",
    "            # a = predict.data[0,0].item()\n",
    "            # b = predict.data[0,1].item()\n",
    "#             # c = predict.data[0,2].item()\n",
    "#             PRED[i, j, 0] = predict.data[0,0].item()\n",
    "#             PRED[i, j, 1] = predict.data[0,1].item()\n",
    "#             PRED[i, j, 2] = predict.data[0,2].item()\n",
    "            # print('a:',a,'b:',b,'c',c)\n",
    "            # print('predict.data',predict.data)\n",
    "            _, predict = torch.max(predict.data, 1)\n",
    "            value = predict.item()\n",
    "            # print(value)\n",
    "            #print(type(value)) #<class 'int'>\n",
    "            nums[i, j] = value\n",
    "      \n",
    "    np.save(SAVE_DATA_DIR + filename.split('.')[-2] + '.npy', nums)\n",
    "#     np.save(SAVE_DATA_DIR + filename.split('.')[-2] + 'value.npy', PRED)\n",
    "    nums = np.repeat(nums[:, :, np.newaxis], 3, axis=2)\n",
    "    #print(nums.shape, nums.dtype)\n",
    "\n",
    "    # nums[:,:,0] = RED, nums[:,:,1] = Green, nums[:,:,2] = Blue\n",
    "    idx_1 = np.where(nums[:,:,0] == 2)  # Index of label 1 (WM)\n",
    "    idx_2 = np.where(nums[:,:,0] == 1)  # Index of label 2 (GM)\n",
    "\n",
    "    # For label 0, leave as black color\n",
    "    # For label 1, set to cyan color: R0G255B255\n",
    "    nums[:,:,0].flat[np.ravel_multi_index(idx_1, nums[:,:,0].shape)] = 0\n",
    "    nums[:,:,1].flat[np.ravel_multi_index(idx_1, nums[:,:,1].shape)] = 255\n",
    "    nums[:,:,2].flat[np.ravel_multi_index(idx_1, nums[:,:,2].shape)] = 255\n",
    "    # For label 2, set to yellow color: R255G255B0\n",
    "    nums[:,:,0].flat[np.ravel_multi_index(idx_2, nums[:,:,0].shape)] = 255\n",
    "    nums[:,:,1].flat[np.ravel_multi_index(idx_2, nums[:,:,1].shape)] = 255\n",
    "    nums[:,:,2].flat[np.ravel_multi_index(idx_2, nums[:,:,2].shape)] = 0\n",
    "\n",
    "    save_img = Image.fromarray(nums, 'RGB')\n",
    "    save_img.save(SAVE_IMG_DIR + filename.split('.')[-2] + '.png')\n",
    "\n",
    "    t.update()\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
